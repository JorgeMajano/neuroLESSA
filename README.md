# ü§ñ neuroLESSA

[cite\_start]**Inteligencia Artificial para la Interpretaci√≥n en tiempo real de la Lengua de Se√±as Salvadore√±a (LESSA) a texto y voz.**

-----

### üìñ Acerca del Proyecto

[cite\_start]En El Salvador, existe una persistente barrera comunicativa entre personas con discapacidad auditiva y la comunidad oyente[cite: 383]. [cite\_start]A pesar de la existencia de soluciones de IA, muchas no est√°n adaptadas a las diferencias ling√º√≠sticas, gestuales y culturales de la **Lengua de Se√±as Salvadore√±a (LESSA)**[cite: 388].

[cite\_start]**neuroLESSA** surge como una soluci√≥n desarrollada espec√≠ficamente para reconocer y procesar se√±as de LESSA [cite: 389][cite\_start], utilizando visi√≥n por computadora y aprendizaje profundo entrenado con datos locales[cite: 389]. [cite\_start]Este proyecto busca promover la inclusi√≥n tecnol√≥gica y el respeto por la identidad ling√º√≠stica de El Salvador[cite: 406].

### üéØ Objetivo Principal

[cite\_start]Desarrollar un prototipo de Inteligencia Artificial capaz de interpretar se√±as de LESSA en tiempo real[cite: 391]. [cite\_start]El sistema utiliza una c√°mara est√°ndar para capturar los gestos y los convierte a **texto y voz**[cite: 392], facilitando la comunicaci√≥n inclusiva.

### ‚ú® Caracter√≠sticas Clave

  * **Interpretaci√≥n en Tiempo Real:** Reconocimiento instant√°neo de se√±as.
  * **Traducci√≥n a Texto:** Muestra la palabra o frase reconocida en pantalla.
  * **Traducci√≥n a Voz:** Utiliza Google Text-to-Speech (gTTS) para verbalizar la se√±a.
  * **Modelo Local:** Entrenado con datos de LESSA, asegurando relevancia cultural.
  * **Interfaz Simple:** Una GUI limpia y f√°cil de usar construida con Tkinter.

### üõ†Ô∏è Tecnolog√≠as Utilizadas

Este proyecto se construye con las siguientes tecnolog√≠as principales:

  * **Python:** Lenguaje base del proyecto.
  * **TensorFlow / Keras:** Para el dise√±o y ejecuci√≥n del modelo de aprendizaje profundo.
  * **OpenCV:** Para la captura y procesamiento de video en tiempo real.
  * [cite\_start]**MediaPipe:** Para la extracci√≥n de puntos de referencia (*landmarks*) de las manos[cite: 459].
  * [cite\_start]**Tkinter:** Para la construcci√≥n de la interfaz gr√°fica de usuario (GUI)[cite: 459].
  * [cite\_start]**gTTS:** Para la funcionalidad de texto a voz[cite: 459].
  * **scikit-learn:** Para utilidades de machine learning.

### üöÄ Instalaci√≥n y Puesta en Marcha

Sigue estos pasos para poner en funcionamiento el proyecto en tu m√°quina local.

**1. Clona el repositorio**

```bash
git clone https://github.com/JorgeMajano/neuroLESSA.git
cd neuroLESSA
```

**2. Crea y activa un entorno virtual**

Se recomienda usar un entorno virtual para manejar las dependencias.

```bash
# Se recomienda Python 3.8, 3.9 o 3.10
python -m venv venv
```

  * En Windows:
    ```bash
    .\venv\Scripts\activate
    ```
  * En macOS/Linux:
    ```bash
    source venv/bin/activate
    ```

**3. Instala las dependencias**

El archivo `requirements.txt` contiene todas las librer√≠as necesarias.

```bash
pip install -r requirements.txt
```

### üèÉ‚Äç‚ôÇÔ∏è Modo de Uso

Una vez que tengas el entorno configurado y las dependencias instaladas, ejecutar la aplicaci√≥n es muy sencillo:

```bash
python camaraVECTORES.py
```

La aplicaci√≥n se iniciar√°, activar√° tu c√°mara principal y abrir√° la interfaz gr√°fica. ¬°Ya puedes comenzar a hacer se√±as\!

### üßë‚Äçüíª Autores

  * [cite\_start]**Jorge Ernesto Majano Santos**
  * [cite\_start]**Richard Jonathan Quinteros Mendoza**

